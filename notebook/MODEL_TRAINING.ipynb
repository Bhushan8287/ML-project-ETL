{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from joblib import dump, load\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:///C:/Users/BW/Desktop/ML project/notebook/mlruns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Customers_Per_Day</th>\n",
       "      <th>Average_Order_Value</th>\n",
       "      <th>Operating_Hours_Per_Day</th>\n",
       "      <th>Number_of_Employees</th>\n",
       "      <th>Marketing_Spend_Per_Day</th>\n",
       "      <th>Location_Foot_Traffic</th>\n",
       "      <th>Daily_Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>6.74</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>106.62</td>\n",
       "      <td>97</td>\n",
       "      <td>1547.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>485</td>\n",
       "      <td>4.50</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>57.83</td>\n",
       "      <td>744</td>\n",
       "      <td>2084.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>398</td>\n",
       "      <td>9.09</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>91.76</td>\n",
       "      <td>636</td>\n",
       "      <td>3118.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320</td>\n",
       "      <td>8.48</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>462.63</td>\n",
       "      <td>770</td>\n",
       "      <td>2912.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156</td>\n",
       "      <td>7.44</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>412.52</td>\n",
       "      <td>232</td>\n",
       "      <td>1663.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number_of_Customers_Per_Day  Average_Order_Value  Operating_Hours_Per_Day  \\\n",
       "0                          152                 6.74                       14   \n",
       "1                          485                 4.50                       12   \n",
       "2                          398                 9.09                        6   \n",
       "3                          320                 8.48                       17   \n",
       "4                          156                 7.44                       17   \n",
       "\n",
       "   Number_of_Employees  Marketing_Spend_Per_Day  Location_Foot_Traffic  \\\n",
       "0                    4                   106.62                     97   \n",
       "1                    8                    57.83                    744   \n",
       "2                    6                    91.76                    636   \n",
       "3                    4                   462.63                    770   \n",
       "4                    2                   412.52                    232   \n",
       "\n",
       "   Daily_Revenue  \n",
       "0        1547.81  \n",
       "1        2084.68  \n",
       "2        3118.39  \n",
       "3        2912.20  \n",
       "4        1663.42  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('coffee_shop_revenue.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Number_of_Customers_Per_Day  2000 non-null   int64  \n",
      " 1   Average_Order_Value          2000 non-null   float64\n",
      " 2   Operating_Hours_Per_Day      2000 non-null   int64  \n",
      " 3   Number_of_Employees          2000 non-null   int64  \n",
      " 4   Marketing_Spend_Per_Day      2000 non-null   float64\n",
      " 5   Location_Foot_Traffic        2000 non-null   int64  \n",
      " 6   Daily_Revenue                2000 non-null   float64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 109.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Customers_Per_Day</th>\n",
       "      <th>Average_Order_Value</th>\n",
       "      <th>Operating_Hours_Per_Day</th>\n",
       "      <th>Number_of_Employees</th>\n",
       "      <th>Marketing_Spend_Per_Day</th>\n",
       "      <th>Location_Foot_Traffic</th>\n",
       "      <th>Daily_Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>274.296000</td>\n",
       "      <td>6.261215</td>\n",
       "      <td>11.667000</td>\n",
       "      <td>7.947000</td>\n",
       "      <td>252.614160</td>\n",
       "      <td>534.893500</td>\n",
       "      <td>1917.325940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>129.441933</td>\n",
       "      <td>2.175832</td>\n",
       "      <td>3.438608</td>\n",
       "      <td>3.742218</td>\n",
       "      <td>141.136004</td>\n",
       "      <td>271.662295</td>\n",
       "      <td>976.202746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.120000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-58.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>130.125000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>1140.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>275.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>250.995000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>1770.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>386.000000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>375.352500</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>2530.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>499.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>499.740000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>5114.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number_of_Customers_Per_Day  Average_Order_Value  \\\n",
       "count                  2000.000000          2000.000000   \n",
       "mean                    274.296000             6.261215   \n",
       "std                     129.441933             2.175832   \n",
       "min                      50.000000             2.500000   \n",
       "25%                     164.000000             4.410000   \n",
       "50%                     275.000000             6.300000   \n",
       "75%                     386.000000             8.120000   \n",
       "max                     499.000000            10.000000   \n",
       "\n",
       "       Operating_Hours_Per_Day  Number_of_Employees  Marketing_Spend_Per_Day  \\\n",
       "count              2000.000000          2000.000000              2000.000000   \n",
       "mean                 11.667000             7.947000               252.614160   \n",
       "std                   3.438608             3.742218               141.136004   \n",
       "min                   6.000000             2.000000                10.120000   \n",
       "25%                   9.000000             5.000000               130.125000   \n",
       "50%                  12.000000             8.000000               250.995000   \n",
       "75%                  15.000000            11.000000               375.352500   \n",
       "max                  17.000000            14.000000               499.740000   \n",
       "\n",
       "       Location_Foot_Traffic  Daily_Revenue  \n",
       "count            2000.000000    2000.000000  \n",
       "mean              534.893500    1917.325940  \n",
       "std               271.662295     976.202746  \n",
       "min                50.000000     -58.950000  \n",
       "25%               302.000000    1140.085000  \n",
       "50%               540.000000    1770.775000  \n",
       "75%               767.000000    2530.455000  \n",
       "max               999.000000    5114.600000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number_of_Customers_Per_Day    0\n",
       "Average_Order_Value            0\n",
       "Operating_Hours_Per_Day        0\n",
       "Number_of_Employees            0\n",
       "Marketing_Spend_Per_Day        0\n",
       "Location_Foot_Traffic          0\n",
       "Daily_Revenue                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model training to get baseline metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"XGBoostRegressor\": XGBRegressor(),\n",
    "    \"KNN\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "def get_baseline_metrics(models_dict, xtrain, ytrain, experiment_name):\n",
    "    cv_type = KFold(n_splits=5, shuffle=True, random_state=3)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    for model_name, model in models_dict.items():\n",
    "        print(f\"Training model: {model_name}\")\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            r2_mean = np.mean(cross_val_score(model, xtrain, ytrain, cv=cv_type, scoring='r2'))\n",
    "            mae_mean = -np.mean(cross_val_score(model, xtrain, ytrain, cv=cv_type, scoring='neg_mean_absolute_error'))\n",
    "            rmse_mean = -np.mean(cross_val_score(model, xtrain, ytrain, cv=cv_type, scoring='neg_root_mean_squared_error'))\n",
    "\n",
    "            mlflow.log_param(\"CV_Type\", \"KFold\")\n",
    "            mlflow.log_param(\"CV_n_splits\", cv_type.n_splits)\n",
    "            mlflow.log_param(\"CV_shuffle\", cv_type.shuffle)\n",
    "            mlflow.log_param(\"CV_random_state\", cv_type.random_state)\n",
    "\n",
    "            mlflow.log_param(\"Model_Name\", model_name)\n",
    "            mlflow.log_metric(\"R2_score\", round(r2_mean, 4))\n",
    "            mlflow.log_metric(\"MAE\", round(mae_mean, 4))\n",
    "            mlflow.log_metric(\"RMSE\", round(rmse_mean, 4))\n",
    "\n",
    "            print(f\"R2 Score: {r2_mean:.4f}\")\n",
    "            print(f\"MAE: {mae_mean:.4f}\")\n",
    "            print(f\"RMSE: {rmse_mean:.4f}\")\n",
    "            print('-' * 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get metrics\n",
    "def get_metrics(ytest, ypred):\n",
    "    r2 = r2_score(ytest, ypred)\n",
    "    mae = mean_absolute_error(ytest, ypred)\n",
    "    rmse = np.sqrt(mean_squared_error(ytest, ypred))\n",
    "    print(f\"R2 score: {r2}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting  the dataset\n",
    "x = data.drop(columns='Daily_Revenue')\n",
    "y = data['Daily_Revenue']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Getting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/03 11:36:42 INFO mlflow.tracking.fluent: Experiment with name 'Baseline metrics using Kfold cv (train splits only)' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LinearRegression\n",
      "R2 Score: 0.8899\n",
      "MAE: 254.3337\n",
      "RMSE: 322.8229\n",
      "-----------------------------------\n",
      "Training model: Ridge\n",
      "R2 Score: 0.8899\n",
      "MAE: 254.3352\n",
      "RMSE: 322.8226\n",
      "-----------------------------------\n",
      "Training model: Lasso\n",
      "R2 Score: 0.8899\n",
      "MAE: 254.3367\n",
      "RMSE: 322.8074\n",
      "-----------------------------------\n",
      "Training model: ElasticNet\n",
      "R2 Score: 0.8872\n",
      "MAE: 257.1948\n",
      "RMSE: 326.6081\n",
      "-----------------------------------\n",
      "Training model: DecisionTreeRegressor\n",
      "R2 Score: 0.8769\n",
      "MAE: 275.3707\n",
      "RMSE: 342.0766\n",
      "-----------------------------------\n",
      "Training model: RandomForestRegressor\n",
      "R2 Score: 0.9412\n",
      "MAE: 188.2082\n",
      "RMSE: 234.3118\n",
      "-----------------------------------\n",
      "Training model: SVR\n",
      "R2 Score: 0.0465\n",
      "MAE: 758.9373\n",
      "RMSE: 952.5776\n",
      "-----------------------------------\n",
      "Training model: XGBoostRegressor\n",
      "R2 Score: 0.9362\n",
      "MAE: 195.5885\n",
      "RMSE: 245.4415\n",
      "-----------------------------------\n",
      "Training model: KNN\n",
      "R2 Score: 0.5278\n",
      "MAE: 527.6643\n",
      "RMSE: 668.3486\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_baseline_metrics(models_dict, xtrain, ytrain, 'Baseline metrics using Kfold cv (train splits only)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **From the EDA correlation analysis, only 3 features show good to weak correlation with the target variable. To evaluate potential improvement, models will be tested using only these 3 correlated features while excluding the remaining ones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_dropped_feat = xtrain.drop(columns=['Operating_Hours_Per_Day', 'Location_Foot_Traffic', 'Number_of_Employees'])\n",
    "xtest_dropped_feat = xtest.drop(columns=['Operating_Hours_Per_Day', 'Location_Foot_Traffic', 'Number_of_Employees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Customers_Per_Day</th>\n",
       "      <th>Average_Order_Value</th>\n",
       "      <th>Marketing_Spend_Per_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>196</td>\n",
       "      <td>8.56</td>\n",
       "      <td>417.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>102</td>\n",
       "      <td>9.89</td>\n",
       "      <td>247.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number_of_Customers_Per_Day  Average_Order_Value  Marketing_Spend_Per_Day\n",
       "333                          196                 8.56                   417.65\n",
       "721                          102                 9.89                   247.26"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_dropped_feat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Customers_Per_Day</th>\n",
       "      <th>Average_Order_Value</th>\n",
       "      <th>Marketing_Spend_Per_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>421</td>\n",
       "      <td>6.30</td>\n",
       "      <td>87.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>239</td>\n",
       "      <td>4.26</td>\n",
       "      <td>192.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number_of_Customers_Per_Day  Average_Order_Value  Marketing_Spend_Per_Day\n",
       "278                          421                 6.30                    87.03\n",
       "492                          239                 4.26                   192.94"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_dropped_feat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/03 11:41:59 INFO mlflow.tracking.fluent: Experiment with name 'Baseline Metrics with Key Features' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LinearRegression\n",
      "R2 Score: 0.8904\n",
      "MAE: 253.8684\n",
      "RMSE: 322.0398\n",
      "-----------------------------------\n",
      "Training model: Ridge\n",
      "R2 Score: 0.8904\n",
      "MAE: 253.8697\n",
      "RMSE: 322.0398\n",
      "-----------------------------------\n",
      "Training model: Lasso\n",
      "R2 Score: 0.8904\n",
      "MAE: 253.8754\n",
      "RMSE: 322.0401\n",
      "-----------------------------------\n",
      "Training model: ElasticNet\n",
      "R2 Score: 0.8876\n",
      "MAE: 256.8567\n",
      "RMSE: 325.9796\n",
      "-----------------------------------\n",
      "Training model: DecisionTreeRegressor\n",
      "R2 Score: 0.8910\n",
      "MAE: 257.5377\n",
      "RMSE: 317.0300\n",
      "-----------------------------------\n",
      "Training model: RandomForestRegressor\n",
      "R2 Score: 0.9439\n",
      "MAE: 186.4513\n",
      "RMSE: 232.4030\n",
      "-----------------------------------\n",
      "Training model: SVR\n",
      "R2 Score: 0.1466\n",
      "MAE: 712.5067\n",
      "RMSE: 901.1858\n",
      "-----------------------------------\n",
      "Training model: XGBoostRegressor\n",
      "R2 Score: 0.9374\n",
      "MAE: 195.9694\n",
      "RMSE: 243.2057\n",
      "-----------------------------------\n",
      "Training model: KNN\n",
      "R2 Score: 0.5432\n",
      "MAE: 515.5839\n",
      "RMSE: 656.5906\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_baseline_metrics(models_dict, xtrain_dropped_feat, ytrain, 'Baseline Metrics with Key Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Baseline Metrics Analysis**\n",
    "\n",
    "To assess the impact of feature selection, i compared the baseline metrics before and after dropping three low-correlation features:  \n",
    "- **Operating_Hours_Per_Day** (-0.0053 correlation)  \n",
    "- **Number_of_Employees** (0.0033 correlation)  \n",
    "- **Location_Foot_Traffic** (0.0134 correlation)  \n",
    "\n",
    "#### **Key Observations:**\n",
    "**Slight Improvement in Linear Models:**  \n",
    "- R² for **LinearRegression, Ridge, and Lasso** improved slightly (~0.0005).  \n",
    "- **MAE and RMSE** slightly decreased, indicating better predictions.  \n",
    "\n",
    "**DecisionTreeRegressor Performed Better:**  \n",
    "- R² improved from **0.8769 → 0.8910**, and RMSE decreased.  \n",
    "\n",
    "**RandomForest and XGBoost Still Strong Performers:**  \n",
    "- **RandomForest R²:** **0.9412 → 0.9439**  \n",
    "- **XGBoost R²:** **0.9362 → 0.9374**  \n",
    "- MAE and RMSE improved slightly.  \n",
    "\n",
    "**SVR and KNN Still Weak Models:**  \n",
    "- **SVR improved slightly** but remains ineffective (low R², high MAE).  \n",
    "- **KNN improved marginally**, but its performance is still subpar.  \n",
    "\n",
    "#### **Conclusion:**\n",
    "Removing low-impact features resulted in a **slight performance boost** across most models, particularly **Linear Regression, Decision Tree, and Ensemble Models (Random Forest & XGBoost)**. These results justify **feature selection** as a valuable preprocessing step before model tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Customers_Per_Day</th>\n",
       "      <th>Average_Order_Value</th>\n",
       "      <th>Marketing_Spend_Per_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>196</td>\n",
       "      <td>8.56</td>\n",
       "      <td>417.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>102</td>\n",
       "      <td>9.89</td>\n",
       "      <td>247.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>343</td>\n",
       "      <td>6.19</td>\n",
       "      <td>282.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>95</td>\n",
       "      <td>4.17</td>\n",
       "      <td>338.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>54</td>\n",
       "      <td>7.80</td>\n",
       "      <td>185.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Number_of_Customers_Per_Day  Average_Order_Value  \\\n",
       "333                           196                 8.56   \n",
       "721                           102                 9.89   \n",
       "1352                          343                 6.19   \n",
       "1680                           95                 4.17   \n",
       "156                            54                 7.80   \n",
       "\n",
       "      Marketing_Spend_Per_Day  \n",
       "333                    417.65  \n",
       "721                    247.26  \n",
       "1352                   282.79  \n",
       "1680                   338.11  \n",
       "156                    185.78  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_dropped_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Customers_Per_Day</th>\n",
       "      <th>Average_Order_Value</th>\n",
       "      <th>Marketing_Spend_Per_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>421</td>\n",
       "      <td>6.30</td>\n",
       "      <td>87.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>239</td>\n",
       "      <td>4.26</td>\n",
       "      <td>192.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>467</td>\n",
       "      <td>5.91</td>\n",
       "      <td>127.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>434</td>\n",
       "      <td>9.74</td>\n",
       "      <td>359.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>466</td>\n",
       "      <td>6.49</td>\n",
       "      <td>133.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Number_of_Customers_Per_Day  Average_Order_Value  \\\n",
       "278                           421                 6.30   \n",
       "492                           239                 4.26   \n",
       "1266                          467                 5.91   \n",
       "557                           434                 9.74   \n",
       "871                           466                 6.49   \n",
       "\n",
       "      Marketing_Spend_Per_Day  \n",
       "278                     87.03  \n",
       "492                    192.94  \n",
       "1266                   127.57  \n",
       "557                    359.67  \n",
       "871                    133.48  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_dropped_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Trying to improve linear models(lin reg, l1, l2 and elastic net).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain_dropped_feat.hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applying log transformation makes the features skewed so transformation step is skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "xtrain_std_scaled = pd.DataFrame(std_scaler.fit_transform(xtrain_dropped_feat), columns=xtrain_dropped_feat.columns)\n",
    "xtest_std_scaled = pd.DataFrame(std_scaler.transform(xtest_dropped_feat), columns=xtest_dropped_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Customers_Per_Day</th>\n",
       "      <th>Average_Order_Value</th>\n",
       "      <th>Marketing_Spend_Per_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.594713</td>\n",
       "      <td>1.063727</td>\n",
       "      <td>1.162863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.317792</td>\n",
       "      <td>1.672344</td>\n",
       "      <td>-0.034669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number_of_Customers_Per_Day  Average_Order_Value  Marketing_Spend_Per_Day\n",
       "0                    -0.594713             1.063727                 1.162863\n",
       "1                    -1.317792             1.672344                -0.034669"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_std_scaled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Customers_Per_Day</th>\n",
       "      <th>Average_Order_Value</th>\n",
       "      <th>Marketing_Spend_Per_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.136061</td>\n",
       "      <td>0.029536</td>\n",
       "      <td>-1.160794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.263943</td>\n",
       "      <td>-0.903982</td>\n",
       "      <td>-0.416440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number_of_Customers_Per_Day  Average_Order_Value  Marketing_Spend_Per_Day\n",
       "0                     1.136061             0.029536                -1.160794\n",
       "1                    -0.263943            -0.903982                -0.416440"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_std_scaled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/03 14:35:06 INFO mlflow.tracking.fluent: Experiment with name 'Key features standard scaled' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LinearRegression\n",
      "R2 Score: 0.8904\n",
      "MAE: 253.8684\n",
      "RMSE: 322.0398\n",
      "-----------------------------------\n",
      "Training model: Ridge\n",
      "R2 Score: 0.8904\n",
      "MAE: 253.8963\n",
      "RMSE: 322.0385\n",
      "-----------------------------------\n",
      "Training model: Lasso\n",
      "R2 Score: 0.8904\n",
      "MAE: 253.9198\n",
      "RMSE: 322.0405\n",
      "-----------------------------------\n",
      "Training model: ElasticNet\n",
      "R2 Score: 0.7931\n",
      "MAE: 345.2430\n",
      "RMSE: 443.3665\n",
      "-----------------------------------\n",
      "Training model: DecisionTreeRegressor\n",
      "R2 Score: 0.8937\n",
      "MAE: 258.5239\n",
      "RMSE: 315.8263\n",
      "-----------------------------------\n",
      "Training model: RandomForestRegressor\n",
      "R2 Score: 0.9428\n",
      "MAE: 187.0007\n",
      "RMSE: 231.7295\n",
      "-----------------------------------\n",
      "Training model: SVR\n",
      "R2 Score: 0.1859\n",
      "MAE: 689.7025\n",
      "RMSE: 880.2349\n",
      "-----------------------------------\n",
      "Training model: XGBoostRegressor\n",
      "R2 Score: 0.9374\n",
      "MAE: 195.9694\n",
      "RMSE: 243.2057\n",
      "-----------------------------------\n",
      "Training model: KNN\n",
      "R2 Score: 0.9396\n",
      "MAE: 189.9169\n",
      "RMSE: 238.3082\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_baseline_metrics(models_dict, xtrain_std_scaled, ytrain, 'Key features standard scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of Standard Scaling vs. No Scaling Results**\n",
    "\n",
    "#### **1. Impact on Linear Models (Linear Regression, Ridge, Lasso, ElasticNet)**\n",
    "- **Linear Regression & Ridge:** No significant change; scaling had no effect.  \n",
    "- **Lasso:** Slight increase in MAE and RMSE after scaling.  \n",
    "- **ElasticNet:** Performance dropped significantly (**R²: 0.7931 vs. 0.8876** before scaling), indicating sensitivity to scaling.  \n",
    "\n",
    "#### **2. Impact on Tree-Based Models (Decision Tree, Random Forest, XGBoost)**\n",
    "- **DecisionTreeRegressor:** Slight improvement after scaling (**R²: 0.8937 vs. 0.8910**).  \n",
    "- **RandomForestRegressor & XGBoost:** No significant impact, confirming that tree-based models do not require scaling.  \n",
    "\n",
    "#### **3. Impact on Distance-Based Models (SVR, KNN)**\n",
    "- **SVR:** Slight improvement (**R²: 0.1466 → 0.1859**) but still performs poorly.  \n",
    "- **KNN:** Major improvement (**R²: 0.5432 → 0.9396**), highlighting the importance of scaling for distance-based models.  \n",
    "\n",
    "### **Conclusion:**\n",
    "____________________\n",
    "- **Scaling had minimal impact on linear models but hurt ElasticNet.**  \n",
    "- **Tree-based models (Decision Tree, Random Forest, XGBoost) do not need scaling.**  \n",
    "- **Distance-based models (KNN, SVR) benefited from scaling, especially KNN.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**                          **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rationale for Hyperparameter Tuning**\n",
    "____________________________________________________\n",
    "\n",
    "### **Why Hyperparameter Tune DecisionTree, RandomForest, XGBoost, and KNN?**\n",
    "- These models have shown **higher performance** than linear models, with **R² > 0.94** in some cases.\n",
    "- They have multiple hyperparameters that **significantly impact performance** and can be optimized for better results.\n",
    "- **KNN benefits from standard scaling**, so tuning its hyperparameters (e.g., `n_neighbors`, `weights`, `metric`) can further improve its performance.\n",
    "\n",
    "### **Why Not Tune Linear Models?**\n",
    "- **LinearRegression, Ridge, and Lasso** already perform well (**R² ≈ 0.89**).\n",
    "- Further tuning (e.g., adjusting `alpha` in Ridge/Lasso) is **unlikely to bring substantial improvements**.\n",
    "\n",
    "### **Why Not Tune SVR?**\n",
    "- SVR performed **significantly worse** (**R² ≈ 0.18**), indicating it is **not well-suited** for this dataset.\n",
    "- Tuning its parameters (e.g., `C`, `epsilon`, `kernel`) is unlikely to bridge the performance gap.\n",
    "- Other models outperform SVR, so focusing on them is a better use of time.\n",
    "\n",
    "### **Conclusion**\n",
    "- Decided to proceed with **hyperparameter tuning for DecisionTree, RandomForest, XGBoost, and KNN** to maximize model performance.  \n",
    "- **Skipping tuning for Linear Models and SVR** due to their **diminishing returns** or poor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving splits\n",
    "xtrain_dropped_feat.to_csv('xtrain split_dropped_features.csv', index=False)\n",
    "xtest_dropped_feat.to_csv('xtest split_dropped_features.csv', index=False)\n",
    "ytrain.to_csv('ytrain.csv', index=False)\n",
    "ytest.to_csv('ytest.csv', index=False)\n",
    "xtrain_std_scaled.to_csv('xtrain_scaled.csv', index=False)\n",
    "xtest_std_scaled.to_csv('xtest_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dtree = {\n",
    "    \"max_depth\": [3, 5, 10, 15, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"ccp_alpha\": [0.0, 0.01, 0.02, 0.05] \n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of boosting rounds\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage\n",
    "    \"max_depth\": [3, 5, 10, 15],  # Tree depth\n",
    "    \"min_child_weight\": [1, 3, 5],  # Minimum sum of weights for child nodes\n",
    "    \"subsample\": [0.6, 0.8, 1.0],  # Subsampling ratio\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],  # Features per tree\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.5]  # Minimum loss reduction for split\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of trees\n",
    "    \"max_depth\": [3, 5, 10, 15, None],  # Tree depth\n",
    "    \"min_samples_split\": [2, 5, 10],  # Min samples to split a node\n",
    "    \"min_samples_leaf\": [1, 2, 4],  # Min samples per leaf\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],  # Feature selection strategy\n",
    "    \"bootstrap\": [True, False]  # Whether to use bootstrapping\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 10],  # Number of neighbors\n",
    "    \"weights\": [\"uniform\", \"distance\"],  # Weighting function\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # Distance metric\n",
    "    \"p\": [1, 2]  # `1 = Manhattan`, `2 = Euclidean`\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/03 15:56:52 INFO mlflow.tracking.fluent: Experiment with name 'Decision Tree Hyperparameter Tuning' does not exist. Creating a new experiment.\n",
      "c:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'ccp_alpha': 0.0, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Root Mean Squared Error (RMSE): 272.0160990439445\n",
      "Mean Absolute Error (MAE): 216.87173287609576\n",
      "R2 Score: 0.9209991623092194\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import json\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "def hyperparameter_tune(model, param_grid, xtrain, ytrain, xtest, ytest, \n",
    "                        experiment_name, run_name, model_name, json_filename):\n",
    "    \"\"\"Performs hyperparameter tuning and logs the best model in MLflow.\"\"\"\n",
    "    \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                               cv=5, scoring='neg_root_mean_squared_error', \n",
    "                               n_jobs=-1, refit=True)\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        grid_search.fit(xtrain, ytrain)\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        predictions = best_model.predict(xtest)\n",
    "\n",
    "        mse = mean_squared_error(ytest, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(ytest, predictions)\n",
    "        r2 = r2_score(ytest, predictions)\n",
    "        \n",
    "        signature = infer_signature(xtrain, best_model.predict(xtrain))\n",
    "        \n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"R2_score\", r2)\n",
    "\n",
    "        # Save parameters to JSON\n",
    "        with open(json_filename, \"w\") as f:\n",
    "            json.dump(best_params, f)\n",
    "        mlflow.log_artifact(json_filename)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(best_model, artifact_path=model_name, signature=signature)\n",
    "\n",
    "        print('-' * 35)\n",
    "        print(f\"Best Parameters for {model_name}:\", best_params)\n",
    "        print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "        print(\"Mean Absolute Error (MAE):\", mae)\n",
    "        print(\"R2 Score:\", r2)\n",
    "        print('-' * 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/03 15:58:30 INFO mlflow.tracking.fluent: Experiment with name 'Random Forests Tree Hyperparameter Tuning' does not exist. Creating a new experiment.\n",
      "c:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': True, 'max_depth': 15, 'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Root Mean Squared Error (RMSE): 219.51626437037703\n",
      "Mean Absolute Error (MAE): 176.53068143972763\n",
      "R2 Score: 0.9485511244964846\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of trees\n",
    "    \"max_depth\": [3, 5, 10, 15, None],  # Tree depth\n",
    "    \"min_samples_split\": [2, 5, 10],  # Min samples to split a node\n",
    "    \"min_samples_leaf\": [1, 2, 4],  # Min samples per leaf\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],  # Feature selection strategy\n",
    "    \"bootstrap\": [True, False]  # Whether to use bootstrapping\n",
    "}\n",
    "\n",
    "\n",
    "rndf_trees_model = RandomForestRegressor(random_state=43)\n",
    "grid_search = GridSearchCV(estimator=rndf_trees_model, param_grid=param_grid_rf, cv=5, scoring='neg_root_mean_squared_error', \n",
    "                           n_jobs=-1, refit=True)\n",
    "\n",
    "mlflow.set_experiment(\"Random Forests Tree Hyperparameter Tuning\")\n",
    "with mlflow.start_run():\n",
    "    grid_search.fit(xtrain_dropped_feat, ytrain)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    predictions = best_model.predict(xtest_dropped_feat)\n",
    "\n",
    "    mse = mean_squared_error(ytest, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(ytest, predictions)\n",
    "    r2 = r2_score(ytest, predictions)\n",
    "\n",
    "    signature = infer_signature(xtrain_dropped_feat, best_model.predict(xtrain_dropped_feat))\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"R2_score\", r2)\n",
    "\n",
    "    with open(\"best_randomforests_tree_params.json\", \"w\") as f:\n",
    "        json.dump(best_params, f)\n",
    "    \n",
    "    mlflow.log_artifact(\"best_randomforests_tree_params.json\")\n",
    "\n",
    "    mlflow.sklearn.log_model(best_model, artifact_path=\"randomforests_tree_hyper_tuned\", signature=signature)\n",
    "    \n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/03 16:06:54 INFO mlflow.tracking.fluent: Experiment with name 'XGBoost Hyperparameter Tuning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost Hyperparameter Tuning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run():\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain_dropped_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m     19\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BW\\Desktop\\ML project\\venv\\lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of boosting rounds\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage\n",
    "    \"max_depth\": [3, 5, 10, 15],  # Tree depth\n",
    "    \"min_child_weight\": [1, 3, 5],  # Minimum sum of weights for child nodes\n",
    "    \"subsample\": [0.6, 0.8, 1.0],  # Subsampling ratio\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],  # Features per tree\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.5]  # Minimum loss reduction for split\n",
    "}\n",
    "\n",
    "xgb_regessor_model = XGBRegressor(random_state=44)\n",
    "grid_search = GridSearchCV(estimator=xgb_regessor_model, param_grid=param_grid_xgb, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1, refit=True)\n",
    "\n",
    "mlflow.set_experiment(\"XGBoost Hyperparameter Tuning\")\n",
    "with mlflow.start_run():\n",
    "    grid_search.fit(xtrain_dropped_feat, ytrain)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    predictions = best_model.predict(xtest_dropped_feat)\n",
    "\n",
    "    mse = mean_squared_error(ytest, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(ytest, predictions)\n",
    "    r2 = r2_score(ytest, predictions)\n",
    "\n",
    "    signature = infer_signature(xtrain_dropped_feat, best_model.predict(xtrain_dropped_feat))\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"R2_score\", r2)\n",
    "\n",
    "    with open(\"best_xgboost_tree_params.json\", \"w\") as f:\n",
    "        json.dump(best_params, f)\n",
    "    \n",
    "    mlflow.log_artifact(\"best_xgboost_tree_params.json\")\n",
    "\n",
    "    mlflow.sklearn.log_model(best_model, artifact_path=\"xgboost_hyper_tuned\", signature=signature)\n",
    "    \n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.xlabel(\"Actual Values (y_test)\")\n",
    "plt.ylabel(\"Predicted Values (y_pred)\")\n",
    "plt.title(\"Scatter Plot of Actual vs Predicted Values\")\n",
    "plt.show()\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(residuals, kde=True, bins=30)\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.title(\"Residual Distribution (Should Be Normally Distributed)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')  # Red line at y=0 for reference\n",
    "plt.xlabel(\"Predicted Values (y_pred)\")\n",
    "plt.ylabel(\"Residuals (y_test - y_pred)\")\n",
    "plt.title(\"Predicted Values vs Residuals (Should Be Uniformly Scattered)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
